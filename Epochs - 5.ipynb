{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b46860f-9cc2-449b-8029-72c426d305c6",
   "metadata": {},
   "source": [
    "Loading Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f944a387-c854-457d-84d9-e480a4ad1396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-tuner) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-tuner) (2.32.4)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->keras-tuner) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optree->keras->keras-tuner) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras-tuner) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras-tuner) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->keras-tuner) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras->keras-tuner) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\upangshu basak\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ff750e-e006-43a1-81e4-2f2444d78515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, utils\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2550e-7dc9-442b-9131-e95cf84955fc",
   "metadata": {},
   "source": [
    "Load & preprocess CIFAR‑10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797d3612-c8f8-43f0-b3b7-4206b8d0c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test  = utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee595b6e-da3e-45a4-a2ff-fa591508b735",
   "metadata": {},
   "source": [
    "MixUp data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe15cba-2ca8-4673-ba1e-efbcb9f89427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_generator(x, y, batch_size=128, alpha=0.2):\n",
    "    n = x.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    while True:\n",
    "        np.random.shuffle(idx)\n",
    "        for i in range(0, n, batch_size):\n",
    "            batch_idx = idx[i : i + batch_size]\n",
    "            x1, y1 = x[batch_idx].copy(), y[batch_idx].copy()\n",
    "            lam = np.random.beta(alpha, alpha, size=len(x1))\n",
    "            lam_x = lam.reshape(-1,1,1,1)\n",
    "            lam_y = lam.reshape(-1,1)\n",
    "            idx2 = np.random.choice(n, size=len(x1), replace=False)\n",
    "            x2, y2 = x[idx2], y[idx2]\n",
    "            x_batch = lam_x * x1 + (1 - lam_x) * x2\n",
    "            y_batch = lam_y * y1 + (1 - lam_y) * y2\n",
    "            yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31854cda-6a87-417f-a18d-861c349654be",
   "metadata": {},
   "source": [
    "Build tunable model using ResNet50 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912c871f-cb55-442c-bf29-02edaa337304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # Backbone\n",
    "    base = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(32,32,3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=(32,32,3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "\n",
    "    # Tunable dense layer size\n",
    "    units = hp.Choice('dense_units', [128, 256, 512], default=256)\n",
    "    x = layers.Dense(units, activation='relu')(x)\n",
    "    x = layers.Dropout(\n",
    "        hp.Float('dropout_rate', min_value=0.3, max_value=0.6, step=0.1, default=0.5)\n",
    "    )(x)\n",
    "\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    # Compile with tunable learning rate and label smoothing\n",
    "    lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log', default=1e-3)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03fb40-b792-4c7d-9c20-fde1d94320b2",
   "metadata": {},
   "source": [
    "Set up Keras Tuner (Hyperband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa10aac-1d29-43c7-bcf2-c91115693526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from cifar5_tuner\\episode5\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='cifar5_tuner',\n",
    "    project_name='episode5'\n",
    ")\n",
    "\n",
    "# Early stopping during tuning\n",
    "stop_early = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a87b788-7f7e-4a05-9e36-570e3e98422e",
   "metadata": {},
   "source": [
    "Run hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbfd86e9-d710-4e53-b724-564e2e1d9364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 15m 40s]\n",
      "val_accuracy: 0.17579999566078186\n",
      "\n",
      "Best val_accuracy So Far: 0.3617999851703644\n",
      "Total elapsed time: 1d 08h 42m 04s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps_per_epoch = x_train.shape[0] // batch_size\n",
    "\n",
    "tuner.search(\n",
    "    mixup_generator(x_train, y_train, batch_size=batch_size, alpha=0.2),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=20,\n",
    "    callbacks=[stop_early]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5846f79-bf33-484e-9910-a8682dea84a2",
   "metadata": {},
   "source": [
    "Retrieve the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d542b31-9e96-4524-9757-ca93fb8eb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa42dd1-a782-4b33-8202-412ec928a7a3",
   "metadata": {},
   "source": [
    "Fine‑tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c8529a-f69c-4f51-adaf-d1a12738c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 235ms/step - accuracy: 0.3290 - loss: 1.9948 - val_accuracy: 0.3576 - val_loss: 1.9121 - learning_rate: 1.3434e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 243ms/step - accuracy: 0.3324 - loss: 1.9926 - val_accuracy: 0.3544 - val_loss: 1.9187 - learning_rate: 1.3434e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 233ms/step - accuracy: 0.3376 - loss: 1.9923 - val_accuracy: 0.3628 - val_loss: 1.9051 - learning_rate: 1.3434e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 235ms/step - accuracy: 0.3354 - loss: 1.9974 - val_accuracy: 0.3441 - val_loss: 1.9216 - learning_rate: 1.3434e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 234ms/step - accuracy: 0.3365 - loss: 1.9883 - val_accuracy: 0.3662 - val_loss: 1.8919 - learning_rate: 1.3434e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 236ms/step - accuracy: 0.3391 - loss: 1.9894 - val_accuracy: 0.3636 - val_loss: 1.8988 - learning_rate: 1.3434e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 241ms/step - accuracy: 0.3444 - loss: 1.9742 - val_accuracy: 0.3764 - val_loss: 1.8865 - learning_rate: 1.3434e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 239ms/step - accuracy: 0.3403 - loss: 1.9782 - val_accuracy: 0.3670 - val_loss: 1.8942 - learning_rate: 1.3434e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 237ms/step - accuracy: 0.3475 - loss: 1.9730 - val_accuracy: 0.3626 - val_loss: 1.9009 - learning_rate: 1.3434e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3416 - loss: 1.9763\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.717239739373326e-05.\n",
      "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 239ms/step - accuracy: 0.3416 - loss: 1.9763 - val_accuracy: 0.3672 - val_loss: 1.8866 - learning_rate: 1.3434e-04\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "source": [
    "fine_tune_history = best_model.fit(\n",
    "    mixup_generator(x_train, y_train, batch_size=batch_size, alpha=0.2),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd895c6-a26b-44f4-82a7-34fb69830a83",
   "metadata": {},
   "source": [
    "Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea786f01-ea54-494b-ab83-1562208e6ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 24s - 75ms/step - accuracy: 0.3764 - loss: 1.8865\n",
      "Final test accuracy: 0.3764\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Final test accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
